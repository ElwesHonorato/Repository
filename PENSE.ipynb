{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Importação da Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import psycopg2\n",
    "from psycopg2 import OperationalError\n",
    "from io import StringIO\n",
    "import seaborn as sns\n",
    "from scipy.stats.stats import pearsonr\n",
    "import csv\n",
    "\n",
    "# Configura para o número de casas decimais que serão informadas após a vírgula.\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cria a conexão com a bases de dados, necessário para execução das consultas.\n",
    "def create_connection(db_name, db_user, db_password, db_host, db_port):\n",
    "    connection = None\n",
    "    try:\n",
    "        connection = psycopg2.connect(\n",
    "            database=db_name,\n",
    "            user=db_user,\n",
    "            password=db_password,\n",
    "            host=db_host,\n",
    "            port=db_port,\n",
    "        )\n",
    "        print(\"Connection to PostgreSQL DB successful\")\n",
    "    except OperationalError as e:\n",
    "        print(f\"The error '{e}' occurred\")\n",
    "    return connection\n",
    "\n",
    "# Execução das consultas no Banco de Dados.            \n",
    "def execute_query(connection, query):\n",
    "    connection.autocommit = True\n",
    "    cursor = connection.cursor()\n",
    "    try:\n",
    "        cursor.execute(query)\n",
    "        print(\"Query executed successfully\")\n",
    "    except OperationalError as e:\n",
    "        print(f\"The error '{e}' occurred\")\n",
    "        \n",
    "# Carga dos dados na base de dados.    \n",
    "def copy_from_stringio(conn, df, table):\n",
    "    \"\"\"\n",
    "    Here we are going save the dataframe in memory \n",
    "    and use copy_from() to copy it to the table\n",
    "    \"\"\"\n",
    "    # save dataframe to an in memory buffer\n",
    "    buffer = StringIO()\n",
    "    df.to_csv(buffer, index=False, header=False,sep=';')\n",
    "    buffer.seek(0)\n",
    "    \n",
    "    cursor = conn.cursor()\n",
    "    try:\n",
    "        cursor.copy_from(buffer, table, sep=\";\")\n",
    "        conn.commit()\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(\"Error: %s\" % error)\n",
    "        conn.rollback()\n",
    "        cursor.close()\n",
    "        return 1\n",
    "    print(\"copy_from_stringio() done\")\n",
    "    cursor.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extração dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leitura dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'C:\\Users\\elwes\\OneDrive\\Documentos\\Projetos\\IBGE - PENSE\\2015\\Amostra 1\\arquivos csv\\PENSE_AMOSTRA1_ALUNOESCOLA.CSV',sep=';')\n",
    "\n",
    "path_dicionario_alunos = r'C:\\Users\\elwes\\OneDrive\\Documentos\\Projetos\\IBGE - PENSE\\2015\\Amostra 1\\Dicionario_PENSE_Microdados_Amostra1.xls'\n",
    "cabecalho_dicionario_alunos = pd.read_excel(path_dicionario_alunos,sheet_name='AMOSTRA1_ALUNO')\n",
    "\n",
    "path_dicionario_escolas = r'C:\\Users\\elwes\\OneDrive\\Documentos\\Projetos\\IBGE - PENSE\\2015\\Amostra 1\\Dicionario_PENSE_Microdados_Amostra1.xls'\n",
    "cabecalho_dicionario_escolas = pd.read_excel(path_dicionario_escolas,sheet_name='AMOSTRA1_ESCOLA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformação dos Dados\n",
    "A príncipio serão realizadas as transformações necessárias para que os dados da tabela de amostras tenham correspondentes descritivos em tabelas que serão posteriormente no sistema de visualização.<br/>\n",
    "Portanto os dados serão divididos em dois grupos:<br/>\n",
    "\n",
    "dados_dicionario_XXXX = Corresponde aos valores únicos possíveis para cada variável.<br/>\n",
    "cabecalho_dicionario_XXXX = Corresponde ao descritivo para cada um dos valores únicos das variáveis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dados_dicionario_alunos = cabecalho_dicionario_alunos.copy()\n",
    "dados_dicionario_escolas = cabecalho_dicionario_escolas.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Dicionários"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dicionário dos Cabeçalhos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coluna criada para posterior classificação, colunas onde o valor True for atribuído serão entendidas como cabeçalho.\n",
    "cabecalho_dicionario_alunos['Filtro'] = False\n",
    "cabecalho_dicionario_alunos['Respondente'] = 'Aluno'\n",
    "# Caso o valor do primeiro caractere não seja um número de 0 à 10 ou '-', este será um cabeçalho.\n",
    "for i,var in enumerate(cabecalho_dicionario_alunos['VARIÁVEL']):\n",
    "    var = str(var)\n",
    "    var_s = [x for x in var]\n",
    "    if var_s[0] not in ['1','2','3','4','5','6','7','8','9','0','-']:\n",
    "        cabecalho_dicionario_alunos.loc[i,['Filtro']] = True      \n",
    "# Reset dos índices, filtro das linhas onde 'Filtro' == True e seleção das colunas.\n",
    "cabecalho_dicionario_alunos.rename({'QUESTIONÁRIO DO ALUNO':'QUESTIONÁRIO'}, axis=1, inplace=True)       \n",
    "cabecalho_dicionario_alunos = cabecalho_dicionario_alunos.loc[cabecalho_dicionario_alunos['Filtro'] == True,['VARIÁVEL','QUESTIONÁRIO','Respondente']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Coluna criada para posterior classificação, colunas onde o valor True for atribuído serão entendidas como cabeçalho.\n",
    "cabecalho_dicionario_escolas['Filtro'] = False\n",
    "cabecalho_dicionario_escolas['Respondente'] = 'Escola'\n",
    "# Caso o valor do primeiro caractere não seja um número de 0 à 10 ou '-', este será um cabeçalho.\n",
    "for i,var in enumerate(cabecalho_dicionario_escolas['VARIÁVEL']):\n",
    "    var = str(var)\n",
    "    var_s = [x for x in var]\n",
    "    if var_s[0] not in ['1','2','3','4','5','6','7','8','9','0','-']:\n",
    "        cabecalho_dicionario_escolas.loc[i,['Filtro']] = True \n",
    "# Reset dos índices, filtro das linhas onde 'Filtro' == True e seleção das colunas.\n",
    "cabecalho_dicionario_escolas.rename({'QUESTIONÁRIO DA ESCOLA':'QUESTIONÁRIO'}, axis=1, inplace=True)       \n",
    "cabecalho_dicionario_escolas = cabecalho_dicionario_escolas.loc[cabecalho_dicionario_escolas['Filtro'] == True,['VARIÁVEL','QUESTIONÁRIO','Respondente']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Junção dos Cabeçalhos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loop para iterar em todas as colunas criando uma lista com o nome da coluna e descricao.\n",
    "lista_colunas_dic_dados = []\n",
    "cabecalho_dicionario_completo = pd.concat([cabecalho_dicionario_alunos, cabecalho_dicionario_escolas]).reset_index()\n",
    "cabecalho_dicionario_completo.drop('index', axis=1, inplace=True)\n",
    "for i in cabecalho_dicionario_completo['VARIÁVEL']:\n",
    "    lista_colunas_dic_dados.append(i)\n",
    "    lista_colunas_dic_dados.append(\"descricao\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dicionário dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Ajuste dos nomes das colunas\n",
    "dados_dicionario_alunos.rename({'VARIÁVEL':'Variável_1','QUESTIONÁRIO DO ALUNO':'Questionário'}, axis=1, inplace=True)\n",
    "dados_dicionario_escolas.rename({'VARIÁVEL':'Variável_1','QUESTIONÁRIO DA ESCOLA':'Questionário'}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Junção dos Dados do Dicionário da Escola e Aluno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Lista para criação do Dicionário de Dados\n",
    "dados_dicionario_raw = pd.concat([dados_dicionario_alunos,dados_dicionario_escolas]).reset_index()\n",
    "dados_dicionario_raw.drop('index', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dicionário vazio com 5000 linhas\n",
    "dicionario_dados_completo = pd.DataFrame(index=range(0,5000),columns = lista_colunas_dic_dados)\n",
    "lista_null = dicionario_dados_completo.iloc[:,0].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ANOPESQ</th>\n",
       "      <th>descricao</th>\n",
       "      <th>PAIS</th>\n",
       "      <th>descricao</th>\n",
       "      <th>REGEOGR</th>\n",
       "      <th>descricao</th>\n",
       "      <th>UFCENSO</th>\n",
       "      <th>descricao</th>\n",
       "      <th>MUNICIPIO_CAP</th>\n",
       "      <th>descricao</th>\n",
       "      <th>...</th>\n",
       "      <th>ESTRATO_EXP</th>\n",
       "      <th>descricao</th>\n",
       "      <th>PESO</th>\n",
       "      <th>descricao</th>\n",
       "      <th>aluno</th>\n",
       "      <th>descricao</th>\n",
       "      <th>escola</th>\n",
       "      <th>descricao</th>\n",
       "      <th>turma</th>\n",
       "      <th>descricao</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>76</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>1</td>\n",
       "      <td>Norte</td>\n",
       "      <td>11</td>\n",
       "      <td>Rondônia</td>\n",
       "      <td>0</td>\n",
       "      <td>Não é capital</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>Nordeste</td>\n",
       "      <td>12</td>\n",
       "      <td>Acre</td>\n",
       "      <td>1100205</td>\n",
       "      <td>Porto Velho</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>Sudeste</td>\n",
       "      <td>13</td>\n",
       "      <td>Amazonas</td>\n",
       "      <td>1200401</td>\n",
       "      <td>Rio Branco</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>Sul</td>\n",
       "      <td>14</td>\n",
       "      <td>Roraima</td>\n",
       "      <td>1302603</td>\n",
       "      <td>Manaus</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>Centro-Oeste</td>\n",
       "      <td>15</td>\n",
       "      <td>Para</td>\n",
       "      <td>1400100</td>\n",
       "      <td>Boa Vista</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4994</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4999 rows × 610 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ANOPESQ descricao PAIS descricao REGEOGR     descricao UFCENSO descricao  \\\n",
       "0        NaN       NaN   76    Brasil       1         Norte      11  Rondônia   \n",
       "1        NaN       NaN  NaN       NaN       2      Nordeste      12      Acre   \n",
       "2        NaN       NaN  NaN       NaN       3       Sudeste      13  Amazonas   \n",
       "3        NaN       NaN  NaN       NaN       4           Sul      14   Roraima   \n",
       "4        NaN       NaN  NaN       NaN       5  Centro-Oeste      15      Para   \n",
       "...      ...       ...  ...       ...     ...           ...     ...       ...   \n",
       "4994     NaN       NaN  NaN       NaN     NaN           NaN     NaN       NaN   \n",
       "4995     NaN       NaN  NaN       NaN     NaN           NaN     NaN       NaN   \n",
       "4996     NaN       NaN  NaN       NaN     NaN           NaN     NaN       NaN   \n",
       "4997     NaN       NaN  NaN       NaN     NaN           NaN     NaN       NaN   \n",
       "4998     NaN       NaN  NaN       NaN     NaN           NaN     NaN       NaN   \n",
       "\n",
       "     MUNICIPIO_CAP      descricao  ... ESTRATO_EXP descricao PESO descricao  \\\n",
       "0                0  Não é capital  ...         NaN       NaN  NaN       NaN   \n",
       "1          1100205    Porto Velho  ...         NaN       NaN  NaN       NaN   \n",
       "2          1200401     Rio Branco  ...         NaN       NaN  NaN       NaN   \n",
       "3          1302603         Manaus  ...         NaN       NaN  NaN       NaN   \n",
       "4          1400100      Boa Vista  ...         NaN       NaN  NaN       NaN   \n",
       "...            ...            ...  ...         ...       ...  ...       ...   \n",
       "4994           NaN            NaN  ...         NaN       NaN  NaN       NaN   \n",
       "4995           NaN            NaN  ...         NaN       NaN  NaN       NaN   \n",
       "4996           NaN            NaN  ...         NaN       NaN  NaN       NaN   \n",
       "4997           NaN            NaN  ...         NaN       NaN  NaN       NaN   \n",
       "4998           NaN            NaN  ...         NaN       NaN  NaN       NaN   \n",
       "\n",
       "     aluno descricao escola descricao turma descricao  \n",
       "0      NaN       NaN    NaN       NaN   NaN       NaN  \n",
       "1      NaN       NaN    NaN       NaN   NaN       NaN  \n",
       "2      NaN       NaN    NaN       NaN   NaN       NaN  \n",
       "3      NaN       NaN    NaN       NaN   NaN       NaN  \n",
       "4      NaN       NaN    NaN       NaN   NaN       NaN  \n",
       "...    ...       ...    ...       ...   ...       ...  \n",
       "4994   NaN       NaN    NaN       NaN   NaN       NaN  \n",
       "4995   NaN       NaN    NaN       NaN   NaN       NaN  \n",
       "4996   NaN       NaN    NaN       NaN   NaN       NaN  \n",
       "4997   NaN       NaN    NaN       NaN   NaN       NaN  \n",
       "4998   NaN       NaN    NaN       NaN   NaN       NaN  \n",
       "\n",
       "[4999 rows x 610 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coluna_dado = -2\n",
    "coluna_descricao = -1\n",
    "linha = -1\n",
    "\n",
    "# O loop abaixo ira iterar entre as tabelas dicionario_dados_completo e dados_dicionario_raw, onde teremos o link entre \n",
    "# o nome da variável, seu valor na tabela da pesquisa e descrição.\n",
    "for i,var in enumerate(dados_dicionario_raw['Variável_1']):\n",
    "    var = str(var)\n",
    "    var_s = [x for x in var]\n",
    "    if var_s[0] not in ['1','2','3','4','5','6','7','8','9','0','-']:\n",
    "        coluna_dado = coluna_dado + 2\n",
    "        coluna_descricao = coluna_descricao + 2        \n",
    "        linha = 0\n",
    "    dicionario_dados_completo.iloc[linha,coluna_dado]      = dados_dicionario_raw['Variável_1'][i]\n",
    "    dicionario_dados_completo.iloc[linha,coluna_descricao] = dados_dicionario_raw['Questionário'][i]\n",
    "    linha = linha + 1\n",
    "dicionario_dados_completo = dicionario_dados_completo[1:]\n",
    "dicionario_dados_completo = dicionario_dados_completo.copy().reset_index()\n",
    "dicionario_dados_completo.drop('index', axis=1,inplace=True)\n",
    "dicionario_dados_completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Algumas colunas não possuem intervalos de valores com uma descrição atríbuida, para estes casos, será iterado na \"dicionario_dados_completo\" buscando por esta condição\n",
    "# e onde  for atendida a mesma seá preenchida com os valores únicos encontrados na coluna correpondente da tabela \"dados\".\n",
    "coluna_dado = 0\n",
    "coluna_descricao = 1\n",
    "linha = -1\n",
    "for i,var in enumerate(lista_colunas_dic_dados):\n",
    "    lista_null_iter = lista_null.copy()\n",
    "    posicao_zero = pd.DataFrame(dicionario_dados_completo[var]).iloc[0,0]\n",
    "#   A coluna 'descricao' será ignorada pois não trata da variável propriamente dita.\n",
    "#   As colunas de 'aluno' e 'turma' possuem muitos registros o que torna esta verificação muito demorada e como neste caso serão objeto de estudo, estas não serão verificadas.\n",
    "    excecoes = ['descricao', 'aluno', 'turma' ]\n",
    "    if var in excecoes:\n",
    "        pass\n",
    "    elif posicao_zero is np.nan:\n",
    "        valores = list(data[var].unique())\n",
    "        for j,var_uni in enumerate(valores):\n",
    "            dicionario_dados_completo.loc[j,var] = var_uni\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ponto de partida para Análise </br>\n",
    "Àfim de definir um ponto de partida para início de pontos relevantes e suas possíveis correlações, foi elaborada a correlação entre todas as variáveis do estudo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VARIÁVEL</th>\n",
       "      <th>VARIÁVEL_2</th>\n",
       "      <th>correlacao</th>\n",
       "      <th>QUESTIONÁRIO_x</th>\n",
       "      <th>QUESTIONÁRIO_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VE01P34</td>\n",
       "      <td>VE01P35</td>\n",
       "      <td>-0.933</td>\n",
       "      <td>A escola fica aberta nos finais de semana para...</td>\n",
       "      <td>As ações desenvolvidas na escola, no final de ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VE01P35</td>\n",
       "      <td>VE01P34</td>\n",
       "      <td>-0.933</td>\n",
       "      <td>As ações desenvolvidas na escola, no final de ...</td>\n",
       "      <td>A escola fica aberta nos finais de semana para...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VE01P13</td>\n",
       "      <td>VE01P14A11</td>\n",
       "      <td>-0.903</td>\n",
       "      <td>Existe algum ponto alternativo de venda de pro...</td>\n",
       "      <td>O ponto alternativo vende frutas frescas ou sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VE01P14A11</td>\n",
       "      <td>VE01P13</td>\n",
       "      <td>-0.903</td>\n",
       "      <td>O ponto alternativo vende frutas frescas ou sa...</td>\n",
       "      <td>Existe algum ponto alternativo de venda de pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VE01P37</td>\n",
       "      <td>VE01P21</td>\n",
       "      <td>-0.898</td>\n",
       "      <td>A escola tem vestiários separados para alunos ...</td>\n",
       "      <td>A escola tem vestiário EM CONDIÇÕES DE USO par...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88483</th>\n",
       "      <td>UFCENSO</td>\n",
       "      <td>ESTRATOGEOREG</td>\n",
       "      <td>1.000</td>\n",
       "      <td>Unidade da Federação</td>\n",
       "      <td>Indicador de estrato georeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88484</th>\n",
       "      <td>UFCENSO</td>\n",
       "      <td>ESTRATOGEOREG</td>\n",
       "      <td>1.000</td>\n",
       "      <td>Unidade da Federação</td>\n",
       "      <td>Indicador de estrato georeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88485</th>\n",
       "      <td>UFCENSO</td>\n",
       "      <td>ESTRATOGEOREG</td>\n",
       "      <td>1.000</td>\n",
       "      <td>Unidade da Federação</td>\n",
       "      <td>Indicador de estrato georeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88486</th>\n",
       "      <td>VB03011A</td>\n",
       "      <td>TEMPOEST</td>\n",
       "      <td>1.000</td>\n",
       "      <td>NOS ÚLTIMOS 7 DIAS, em quantos dias você fez a...</td>\n",
       "      <td>A atividade física globalmente estimada refere...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88487</th>\n",
       "      <td>TEMPOEST</td>\n",
       "      <td>VB03011A</td>\n",
       "      <td>1.000</td>\n",
       "      <td>A atividade física globalmente estimada refere...</td>\n",
       "      <td>NOS ÚLTIMOS 7 DIAS, em quantos dias você fez a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88488 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         VARIÁVEL     VARIÁVEL_2  correlacao  \\\n",
       "0         VE01P34        VE01P35      -0.933   \n",
       "1         VE01P35        VE01P34      -0.933   \n",
       "2         VE01P13     VE01P14A11      -0.903   \n",
       "3      VE01P14A11        VE01P13      -0.903   \n",
       "4         VE01P37        VE01P21      -0.898   \n",
       "...           ...            ...         ...   \n",
       "88483     UFCENSO  ESTRATOGEOREG       1.000   \n",
       "88484     UFCENSO  ESTRATOGEOREG       1.000   \n",
       "88485     UFCENSO  ESTRATOGEOREG       1.000   \n",
       "88486    VB03011A       TEMPOEST       1.000   \n",
       "88487    TEMPOEST       VB03011A       1.000   \n",
       "\n",
       "                                          QUESTIONÁRIO_x  \\\n",
       "0      A escola fica aberta nos finais de semana para...   \n",
       "1      As ações desenvolvidas na escola, no final de ...   \n",
       "2      Existe algum ponto alternativo de venda de pro...   \n",
       "3      O ponto alternativo vende frutas frescas ou sa...   \n",
       "4      A escola tem vestiários separados para alunos ...   \n",
       "...                                                  ...   \n",
       "88483                               Unidade da Federação   \n",
       "88484                               Unidade da Federação   \n",
       "88485                               Unidade da Federação   \n",
       "88486  NOS ÚLTIMOS 7 DIAS, em quantos dias você fez a...   \n",
       "88487  A atividade física globalmente estimada refere...   \n",
       "\n",
       "                                          QUESTIONÁRIO_y  \n",
       "0      As ações desenvolvidas na escola, no final de ...  \n",
       "1      A escola fica aberta nos finais de semana para...  \n",
       "2      O ponto alternativo vende frutas frescas ou sa...  \n",
       "3      Existe algum ponto alternativo de venda de pro...  \n",
       "4      A escola tem vestiário EM CONDIÇÕES DE USO par...  \n",
       "...                                                  ...  \n",
       "88483                        Indicador de estrato georeg  \n",
       "88484                        Indicador de estrato georeg  \n",
       "88485                        Indicador de estrato georeg  \n",
       "88486  A atividade física globalmente estimada refere...  \n",
       "88487  NOS ÚLTIMOS 7 DIAS, em quantos dias você fez a...  \n",
       "\n",
       "[88488 rows x 5 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlacao = data.corr()\n",
    "correlacao.reset_index(inplace=True)\n",
    "correlacao.rename({'index':'VARIÁVEL'}, axis=1, inplace=True)\n",
    "correlacao.to_csv(r'C:\\Users\\elwes\\OneDrive\\Documentos\\Projetos\\IBGE - PENSE\\2015\\Amostra 1\\df_correlacao_questionario.CSV')\n",
    "\n",
    "df_correlacao_questionario = correlacao.melt(    id_vars = ['VARIÁVEL'],\n",
    "                                    var_name = ['VARIÁVEL_2'],\n",
    "                                    value_name = \"correlacao\")\n",
    "df_correlacao_questionario = df_correlacao_questionario.dropna()\n",
    "df_correlacao_questionario = df_correlacao_questionario.loc[df_correlacao_questionario['VARIÁVEL'] != df_correlacao_questionario['VARIÁVEL_2'],]\n",
    "df_correlacao_questionario = df_correlacao_questionario.sort_values(['correlacao'])\n",
    "df_correlacao_questionario = pd.merge(df_correlacao_questionario,cabecalho_dicionario_completo[['VARIÁVEL','QUESTIONÁRIO']], on=['VARIÁVEL'],how='left')\n",
    "cabecalho_dicionario_completo.rename({'VARIÁVEL':'VARIÁVEL_2'}, axis=1, inplace=True)\n",
    "df_correlacao_questionario = pd.merge(df_correlacao_questionario,cabecalho_dicionario_completo[['VARIÁVEL_2','QUESTIONÁRIO']], on=['VARIÁVEL_2'],how='left')\n",
    "cabecalho_dicionario_completo.rename({'VARIÁVEL_2':'VARIÁVEL'}, axis=1, inplace=True)\n",
    "df_correlacao_questionario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criação das Tabelas Dimensão em SQL\n",
    "Nessa etapa todas as tabelas dimensão foram exportadas para arquivos individuais e o comando SQL para criação das tabelas foi elaborado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Variável 'sql_create_d_tables' onde serão armazenados os comandos para criação de todas as tabelas dimensão extraídos do dicionário.\n",
    "sql_create_d_tables = ''\n",
    "# Lista com o nome de todas as tabelas à serem carregadas no banco de dados.\n",
    "list_of_d_tables = []\n",
    "# Lista com os Dataframes à serem carregados no banco de dados\n",
    "dfs_d_tables = []\n",
    "# O Dataframe da posição dfs_d_tables[0] corresponde ao nome list_of_d_tables[0], essa relação será utilizada para criação do loop\n",
    "# de criação dos comandos SQL.\n",
    "\n",
    "# Caminho para salvar as tabelas dimensão em .CSV, não serão utilizadas posteriormente neste pois serão utilizadas as tabelas já\n",
    "# carregadas durante a execução\n",
    "tabela_dic_path = 'C:\\\\Users\\\\elwes\\\\OneDrive\\\\Documentos\\\\Projetos\\\\IBGE - PENSE\\\\2015\\\\Amostra 1\\\\tabelas_dicionarios\\\\'\n",
    "\n",
    "# Posição inicial para iniciar criação das tabelas dimensão para utilizar no While à seguir.\n",
    "i = 0 # o Índice 'i' ficará responsável por selecionar as variáveis \n",
    "# Loop para iterar em todas as colunas do colunas do Dicionario de Dados\n",
    "while i < len(dicionario_dados_completo.columns):\n",
    "    j = i + 2 # o Índice 'j' será responsável por selecionar a coluna de descrição correspondente a variável\n",
    "    # Lembrete: Quando o range i:j é selecionado temos na posição inicial \"0:2\", o padrão de seleção é 'up to but not included', ou seja,\n",
    "    # a coluna 2 não é selecionada, assim temos a seleção das colunas 0:1.\n",
    "    temp = dicionario_dados_completo.iloc[:,i:j] # Tabela contendo apenas os dados referentes a variável 'dicionario_dados_completo.columns[i]'\n",
    "    temp.dropna(axis=0, how='all', inplace=True) # Remoção das linhas com valores nulos\n",
    "    temp.reset_index() # Reset do index\n",
    "    temp.to_csv(tabela_dic_path + temp.columns[0] + '.csv' ) # Exportação para um arquivo .CSV\n",
    "    # Temos variáveis comuns no dicionario Escola e Aluno portanto, no momento da elaboração da lista de à serem carregas no banco de dados\n",
    "    # precisamos incluir os dados apenas uma vez, dessa forma a condicação if seguinte verifica se a variável em questão já foi incluída na lista\n",
    "    # em caso afirmativo passamos ao próximo loop.\n",
    "    if temp.columns[0] in list_of_d_tables:\n",
    "        i = i + 2 # Incremento na indice selecionador de colunas.\n",
    "        continue\n",
    "    # Lista com o nome dos Dataframes\n",
    "    list_of_d_tables.append(temp.columns[0])\n",
    "    # Lista com os Dataframes, cada posição da lista corresponde à um Dataframe.\n",
    "    dfs_d_tables.append(temp)\n",
    "    \n",
    "    # Comando SQL para criação das tabelas dimensão. \n",
    "    sql_create_d_tables= sql_create_d_tables + 'CREATE TABLE IF NOT EXISTS ' + temp.columns[0] + ' ( \\n'\n",
    "    var_type = 'TEXT' \n",
    "    for j, column in enumerate(temp.columns):\n",
    "        if j < len(temp.columns)-1:\n",
    "            sql_create_d_tables = sql_create_d_tables + column + '\\t' + var_type + ',\\n'\n",
    "        else :  \n",
    "            sql_create_d_tables = sql_create_d_tables + column + '\\t' + var_type + '\\n'\n",
    "    sql_create_d_tables = sql_create_d_tables + ');\\n\\n'    \n",
    "    i = i + 2 # Incremento na indice selecionador de colunas.\n",
    "# Exportação do comando SQL para um arquivo .txt   \n",
    "with open('sql_create_d_tables.txt', mode='w') as txtfile:\n",
    "    txtfile.write(sql_create_d_tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criação Base de Dados AWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "connection = create_connection('postdb',\n",
    "                                  'elweshonorato',\n",
    "                                  'Andromeda=2121',\n",
    "                                  'main.czqwwerei65b.us-east-2.rds.amazonaws.com',\n",
    "                                  '5432')\n",
    "\n",
    "create_db_pense_ibge_query = \"CREATE DATABASE pense_ibge\"\n",
    "execute_query(connection, create_db_pense_ibge_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criação das Tabelas Dimensão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "connection = create_connection('pense_ibge',\n",
    "                               'elweshonorato',\n",
    "                               'Andromeda=2121',\n",
    "                               'main.czqwwerei65b.us-east-2.rds.amazonaws.com',\n",
    "                               '5432')\n",
    "\n",
    "execute_query(connection, sql_create_d_tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga dos Dados nas Tabelas Dimensão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "connection = create_connection('pense_ibge',\n",
    "                               'elweshonorato',\n",
    "                               'Andromeda=2121',\n",
    "                               'main.czqwwerei65b.us-east-2.rds.amazonaws.com',\n",
    "                               '5432')\n",
    "\n",
    "for i,df in enumerate(list_of_d_tables):\n",
    "    copy_from_stringio(connection, dfs_d_tables[i],     df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criação da Tabela Fato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_create_f_tables = ''\n",
    "sql_create_f_tables= sql_create_f_tables + 'CREATE TABLE IF NOT EXISTS f_dados_pesquisa' + ' ( \\n'\n",
    "var_type = 'TEXT'\n",
    "for j, column in enumerate(data.columns):\n",
    "    if j < len(data.columns)-1:\n",
    "        sql_create_f_tables = sql_create_f_tables + column + '\\t' + var_type + ',\\n'\n",
    "    else :  \n",
    "        sql_create_f_tables = sql_create_f_tables + column + '\\t' + var_type + '\\n'\n",
    "        sql_create_f_tables = sql_create_f_tables + ');\\n\\n'\n",
    "    \n",
    "with open('sql_create_f_tables.txt', mode='w') as txtfile:\n",
    "    txtfile.write(sql_create_f_tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga dos Dados na Tabela Fato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "connection = create_connection('pense_ibge',\n",
    "                               'elweshonorato',\n",
    "                               'Andromeda=2121',\n",
    "                               'main.czqwwerei65b.us-east-2.rds.amazonaws.com',\n",
    "                               '5432')\n",
    "execute_query(connection, sql_create_f_tables)\n",
    "copy_from_stringio(connection, data, 'f_dados_pesquisa')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
